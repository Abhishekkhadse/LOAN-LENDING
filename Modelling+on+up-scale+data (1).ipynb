{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\Dell\\Desktop\\Finalproject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting\n",
    "y_train = np.array(train['default_ind'])  \n",
    "y_test = np.array(test['default_ind'])\n",
    "X_train = train.drop('default_ind', axis = 1)  \n",
    "X_train = np.array(X_train)\n",
    "X_test = test.drop('default_ind', axis = 1)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(X_test)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(X_test)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#up_sampling \n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    199733\n",
       "0    199733\n",
       "Name: default_ind, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes for train\n",
    "df_majority_train = train[train.default_ind==0]\n",
    "df_minority_train = train[train.default_ind==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority_train, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=199733,    # to match majority class\n",
    "                                 random_state=111) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled_train = pd.concat([df_majority_train, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled_train.default_ind.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Separate input features (X) and target variable (y)\n",
    "y_train1 = df_upsampled_train.default_ind\n",
    "X_train1 = df_upsampled_train.drop('default_ind', axis=1)\n",
    "y_train1 = np.array(y_train1)\n",
    "X_train1 = np.array(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier=(LogisticRegression())\n",
    "#fitting traing data to model\n",
    "classifier.fit(X_train1,y_train1)\n",
    "Y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4516 3532]\n",
      " [  87  162]]\n",
      "Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.56      0.71      8048\n",
      "          1       0.04      0.65      0.08       249\n",
      "\n",
      "avg / total       0.95      0.56      0.69      8297\n",
      "\n",
      "Accuracy of the model: 0.563818247559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60586780521689132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report :\")\n",
    "print(classification_report(y_test,Y_pred))\n",
    "accuracy_score=accuracy_score(y_test,Y_pred)\n",
    "print(\"Accuracy of the model:\",accuracy_score)\n",
    "#auc curve \n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, Y_pred)\n",
    "auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50575012  0.49424988]\n",
      " [ 0.51704498  0.48295502]\n",
      " [ 0.50030051  0.49969949]\n",
      " ..., \n",
      " [ 0.48140435  0.51859565]\n",
      " [ 0.49338639  0.50661361]\n",
      " [ 0.51996448  0.48003552]]\n"
     ]
    }
   ],
   "source": [
    "#%% Adjusting threshold\n",
    "#store the predicted probabilities\n",
    "y_pred_prob = classifier.predict_proba(X_test)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_class=[]\n",
    "for value in y_pred_prob[:,0]:\n",
    "    if value < 0.495:\n",
    "        y_pred_class.append(1)\n",
    "    else:\n",
    "        y_pred_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5234 2814]\n",
      " [ 104  145]]\n",
      "Accuracy of the model:  0.648306616849\n",
      "Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.65      0.78      8048\n",
      "          1       0.05      0.58      0.09       249\n",
      "\n",
      "avg / total       0.95      0.65      0.76      8297\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61633861489696362"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cfm=confusion_matrix(y_test.tolist(),y_pred_class)\n",
    "print(cfm)\n",
    "accuracy_score=accuracy_score(y_test.tolist(),y_pred_class)\n",
    "print(\"Accuracy of the model: \",accuracy_score)\n",
    "print(\"Classification report :\")\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "#auc curve \n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_class)\n",
    "auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DecisionTree=DecisionTreeClassifier()\n",
    "model_DecisionTree.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred=model_DecisionTree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8048    0]\n",
      " [ 249    0]]\n",
      "Accuracy of the model:  0.969989152706\n",
      "Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      8048\n",
      "          1       0.00      0.00      0.00       249\n",
      "\n",
      "avg / total       0.94      0.97      0.96      8297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cfm=confusion_matrix(y_test.tolist(),Y_pred)\n",
    "print(cfm)\n",
    "accuracy_score=accuracy_score(y_test.tolist(),Y_pred)\n",
    "print(\"Accuracy of the model: \",accuracy_score)\n",
    "print(\"Classification report :\")\n",
    "print(classification_report(y_test,Y_pred))\n",
    "#auc curve \n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, Y_pred)\n",
    "auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using xgboost\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "my_model = XGBRegressor(learning_rate =0.09,subsample=0.5,colsample_bytree=0.85,reg_alpha=0.005,min_child_weight = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.85, gamma=0, learning_rate=0.09,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=5, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0.005, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(X_train1, y_train1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance  test :  0.568172790566\n"
     ]
    }
   ],
   "source": [
    "test_y_pred = my_model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, test_y_pred)\n",
    "print(\"Performance  test : \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
